import dotenv from 'dotenv';
import { OpenAI } from 'openai';
import { ChatCompletionMessageParam } from 'openai/resources';
// Importar LRUCache correctamente
import LRUCache from 'lru-cache';

dotenv.config();

// Constantes para emoticones por categor√≠a
const EMOJIS = {
  perfume: ['‚ú®', 'üí´', 'üå∏', 'üíê', 'üåπ', 'üîÆ'],
  personality: ['üòä', 'ü§î', 'üí≠', 'üí´', '‚ú®'],
  occasion: ['üé≠', 'üëî', 'üéâ', 'üíº', 'üåÉ'],
  greeting: ['üëã', '‚ú®', 'üåü', 'üí´'],
  question: ['‚ùì', 'ü§î', 'üí≠']
};

// Configuraci√≥n b√°sica
const CONFIG = {
  model: 'gpt-4o',
  temperature: 0.7,
  maxTokens: 250,
  cacheMaxSize: 100,
  cacheTTL: 1000 * 60 * 60, // 1 hora en milisegundos
  defaultLanguage: 'es' as 'es' | 'en'
};

// Verificar clave API
if (!process.env.OPENAI_API_KEY) {
  console.error('‚ùå ERROR: No se ha encontrado OPENAI_API_KEY');
  process.exit(1);
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Crear cach√© para respuestas frecuentes
const responseCache = new LRUCache({
  max: CONFIG.cacheMaxSize,
  ttl: CONFIG.cacheTTL
});

// Selecciona un emotic√≥n aleatorio de una categor√≠a
function getRandomEmoji(category: keyof typeof EMOJIS): string {
  const emojis = EMOJIS[category];
  return emojis[Math.floor(Math.random() * emojis.length)];
}

// Maneja la selecci√≥n inicial de idioma
export function handleLanguageSelection(selectedLanguage: string): string {
  if (selectedLanguage.toLowerCase() === 'espa√±ol') {
    return `¬°Hola! ${getRandomEmoji('greeting')} Soy AROMASENS, tu asesor personal de perfumes. Para ayudarte a encontrar la fragancia perfecta, ¬øpodr√≠as compartirme tu edad?`;
  } else {
    return `Hello! ${getRandomEmoji('greeting')} I'm AROMASENS, your personal fragrance advisor. To help you find the perfect scent, could you share your age with me?`;
  }
}

// Genera un perfil psicol√≥gico y recomendaci√≥n de perfume inventado personalizado
export async function generatePerfumeProfile(
  preferences: any, 
  conversationHistory: ChatCompletionMessageParam[] = []
): Promise<any> {
  try {
    // Verificar si la respuesta est√° en cach√©
    const cacheKey = `profile:${JSON.stringify(preferences)}:${JSON.stringify(conversationHistory)}`;
    const cachedResponse = responseCache.get(cacheKey);
    if (cachedResponse) {
      return cachedResponse;
    }

    const prompt = `
    Eres AROMASENS, un asesor experto en perfumer√≠a de lujo AROMASENS, boutique especializada en perfumes exclusivos. Bas√°ndote en la conversaci√≥n con el cliente, crea un perfil psicol√≥gico detallado y recomienda un perfume inventado √∫nico de la colecci√≥n AROMASENS.
    
    Analiza a profundidad las preferencias del cliente:
    - G√©nero preferido: ${preferences.gender || 'No especificado'}
    - Edad aproximada: ${preferences.age || 'No especificada'}
    - Experiencia con perfumes: ${preferences.experience || 'No especificada'}
    - Ocasi√≥n de uso: ${preferences.occasion || 'No especificada'}
    - Preferencias olfativas: ${preferences.preferences || 'No especificadas'}
    - Rasgos de personalidad: ${preferences.personality || 'No especificados'}
    
    Crea un perfume inventado de AROMASENS con:
    1. Un nombre sofisticado y exclusivo
    2. Una historia o inspiraci√≥n √∫nica
    3. Notas de salida, coraz√≥n y fondo detalladas
    4. Una descripci√≥n de la personalidad que refleja
    5. Ocasiones ideales para usarlo
    
    Responde en formato JSON con esta estructura:
    {
      "psychologicalProfile": "An√°lisis psicol√≥gico detallado del cliente",
      "recommendedPerfume": {
        "id": [n√∫mero aleatorio entre 1000-9999],
        "name": "Nombre exclusivo del perfume",
        "brand": "AROMASENS",
        "story": "Historia o inspiraci√≥n detr√°s del perfume",
        "notes": ["Nota 1", "Nota 2", "Nota 3", "Nota 4", "Nota 5"],
        "personalityMatch": "Descripci√≥n de c√≥mo el perfume refleja la personalidad del cliente",
        "occasions": ["Ocasi√≥n 1", "Ocasi√≥n 2", "Ocasi√≥n 3"]
      },
      "recommendationReason": "Raz√≥n personalizada por la que este perfume es perfecto para el cliente"
    } venta y comercializacion de esencias que van de acuerdo a tu personalidad y gustos.

    ## INFORMACI√ìN DEL CLIENTE
    - G√©nero: ${preferences.gender || 'No especificado'}
    - Edad: ${preferences.age || 'No especificado'}
    - Experiencia: ${preferences.experience || 'No especificado'}
    - Ocasi√≥n: ${preferences.occasion || 'No especificado'}
    - Preferencias: ${preferences.preferences || 'No especificado'}
    - Personalidad: ${preferences.personality || 'No especificado'}

    ## INSTRUCCIONES
    1. Analiza el perfil psicol√≥gico basado en los datos proporcionados.
    2. Selecciona una fragancia espec√≠fica (ID entre 1-20) que mejor se adapte.
    3. S√© conciso pero informativo.

    Devuelve √öNICAMENTE un objeto JSON con:
    {
      "psychologicalProfile": "An√°lisis psicol√≥gico breve",
      "recommendedPerfumeId": n√∫mero entre 1 y 20,
      "recommendationReason": "Explicaci√≥n concisa en formato markdown"
    }
    `;

    // Preparar mensajes para la API
    const messages: ChatCompletionMessageParam[] = [
      { 
        role: 'system', 
        content: 'Eres AROMASENS, un asesor de perfumer√≠a conciso.' 
      },
      ...conversationHistory,
      { role: 'user', content: prompt }
    ];

    const response = await openai.chat.completions.create({
      model: CONFIG.model,
      messages,
      response_format: { type: 'json_object' },
      temperature: CONFIG.temperature,
      max_tokens: CONFIG.maxTokens
    });
    
    const content = response.choices[0].message.content || '{}';
    const result = JSON.parse(content);
    
    // Guardar en cach√©
    responseCache.set(cacheKey, result);
    
    return result;
  } catch (error) {
    console.error('Error generando perfil:', error);
    throw new Error('Error al generar perfil: ' + (error as Error).message);
  }
}

// Funci√≥n para generar respuestas de chat
export async function generateChatResponse(
  prompt: string, 
  language: 'es' | 'en' = CONFIG.defaultLanguage,
  conversationHistory: ChatCompletionMessageParam[] = []
): Promise<string> {
  try {
    // Verificar si la respuesta est√° en cach√©
    const cacheKey = `chat:${language}:${prompt}:${JSON.stringify(conversationHistory)}`;
    const cachedResponse = responseCache.get(cacheKey);
    if (cachedResponse) {
      return cachedResponse as string;
    }

    const systemPrompt = language === 'es' 
      ? 'Eres un asistente amigable de tienda de perfumes. Mant√©n tus respuestas concisas y en espa√±ol.'
      : 'You are a friendly perfume store assistant. Keep your responses concise and in English.';

    const response = await openai.chat.completions.create({
      model: CONFIG.model,
      messages: [
        { role: 'system', content: systemPrompt },
        ...conversationHistory,
        { role: 'user', content: prompt }
      ],
      temperature: CONFIG.temperature,
      max_tokens: CONFIG.maxTokens
    });

    const content = response.choices[0].message.content || 
      (language === 'es' 
        ? "Lo siento, no pude generar una respuesta." 
        : "Sorry, I couldn't generate a response.");
    
    // Guardar en cach√©
    responseCache.set(cacheKey, content);
    
    return content;
  } catch (error) {
    console.error('Error generando respuesta de chat:', error);
    return language === 'es'
      ? `Lo siento ${getRandomEmoji('question')}, estoy teniendo problemas para procesar tu mensaje. ¬øPodr√≠as intentarlo de nuevo?`
      : `Sorry ${getRandomEmoji('question')}, I'm having trouble processing your message. Could you try again?`;
  }
}

